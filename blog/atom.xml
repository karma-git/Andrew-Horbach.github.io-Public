<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog</id>
    <title>Andrew Horbach Blog</title>
    <updated>2022-12-31T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog"/>
    <subtitle>Andrew Horbach Blog</subtitle>
    <icon>https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Helm vs Python validation]]></title>
        <id>helm-vs-python</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/helm-vs-python"/>
        <updated>2022-12-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Я ненавижу helm]]></summary>
        <content type="html"><![CDATA[<p>Решали с коллегами задачу по генерации манифестов <strong>Provisioner</strong> в цикле, при таком создании есть один деструктивный момент - нужно выбрать Container Runtime Interface (CRI), иначе  <code>provisioner.spec.kubeletConfiguration.containerRuntime</code> в манифесте <strong>Provisioner</strong>, то в паре с <strong>AWSNodeTemplate</strong> karpenter по дефолту будет выставлен в <code>containerd</code> (<a href="https://github.com/aws/karpenter/blob/7241f43569d6878056f3251667b4689684071401/pkg/cloudprovider/launchtemplate_test.go#L894">подтверждение в тесте</a>)</p><p>Собрали ряд требований:</p><ul><li>CRI не указан в провиженере, значит выбираем дефолтный для нас (в нашем случае dockerd)</li><li>CRI указан в провиженере, выбираем его</li><li>CRI не указан в провиженере, но в <code>provisioner.spec.kubeletConfiguration</code> есть другие параметры</li></ul><p>Получился следующий код валидации:</p><h2>helm</h2><pre><code class="language-yaml">  # Kubelet
  # If Provisioner.kubeletConfiguration is not empty
  {{- if .kubeletConfiguration }}
  kubeletConfiguration:
    # If containerRuntime has been configured in Provisioner.kubeletConfiguration
    {{- if hasKey .kubeletConfiguration &quot;containerRuntime&quot; -}}
      {{- toYaml .kubeletConfiguration | nindent 4 }}
    # ElseIf containerRuntime has not been configured in Provisioner.kubeletConfiguration
    {{- else }}
      # Pick default CRI from karpenter.default.kubeletConfiguration and add it to current .kubeletConfiguration
      {{- $CRI := dict &quot;containerRuntime&quot; $.Values.karpenter.default.kubeletConfiguration.containerRuntime -}}
      {{- $kubeletConfiguration := merge $CRI .kubeletConfiguration }}
      {{- toYaml $kubeletConfiguration | nindent 4 }}
    {{- end }}
  # ElseIf Provisioner.kubeletConfiguration is empty
  {{- else }}
  kubeletConfiguration:
      {{- toYaml $.Values.karpenter.default.kubeletConfiguration | nindent 4 }}
  {{- end }}
</code></pre><details><summary>Тесты</summary><p>Test cases:</p><ul><li>1) CRI не указан в провиженере
values.yml</li></ul><pre><code class="language-yaml">karpenter:
  payload:
    ahorbach:
      foo: bar
</code></pre><p>result:</p><pre><code class="language-yaml">spec:
  # Kubelet
  # If Provisioner.kubeletConfiguration is not empty
  kubeletConfiguration:
    containerRuntime: dockerd
</code></pre><ul><li>2) CRI указан в провиженере</li></ul><p>values.yml</p><pre><code class="language-yaml">karpenter:
  payload:
    ahorbach:
      kubeletConfiguration:
        bar: baz
        containerRuntime: rocket
</code></pre><p>result:</p><pre><code class="language-yaml">spec:
  # Kubelet
  # If Provisioner.kubeletConfiguration is not empty
  kubeletConfiguration:
    # If containerRuntime has been configured in Provisioner.kubeletConfiguration
    bar: baz
    containerRuntime: rocket
    # ElseIf containerRuntime has not been configured in Provisioner.kubeletConfiguration
  # ElseIf Provisioner.kubeletConfiguration is empty
</code></pre><ul><li>3) CRI не указан в провиженере, но есть конфиг</li></ul><p>values.yml</p><pre><code class="language-yaml">  payload:
    ahorbach:
      kubeletConfiguration:
        spam: eggs
</code></pre><p>result:</p><pre><code class="language-yaml">spec:
  # Kubelet
  # If Provisioner.kubeletConfiguration is not empty
  kubeletConfiguration:
    # If containerRuntime has been configured in Provisioner.kubeletConfiguration
      # Pick default CRI from karpenter.default.kubeletConfiguration and add it to current .kubeletConfiguration
    containerRuntime: dockerd
    spam: eggs
</code></pre></details><h2>python</h2><pre><code class="language-python">from pydantic import BaseModel, validator

DEFAULT_CRI = {&quot;containerRuntime&quot;: &quot;dockerd&quot;}

class karpenterPayloadProvisioner(BaseModel):
  name: str
  kubelet_configuration: dict = DEFAULT_CRI

  @validator(&#x27;kubelet_configuration&#x27;)
  def kubelet_container_runtime(cls, v):
    cri = v.get(&quot;containerRuntime&quot;)
    # option two - Mutating
    if cri not in [&quot;dockerd&quot;, &quot;containerd&quot;]:
      v.update(DEFAULT_CRI)
    return v
</code></pre><details><summary>Тесты</summary><pre><code class="language-python">import typing as t

import pytest

from karpenter import karpenterPayloadProvisioner

# without selected CRI in Provisioner
case1 = (&quot;foo&quot;, {}, &quot;dockerd&quot;)

# with containerd as a CRI for Provisioner

case2 = (&quot;bar&quot;, {&quot;kubeReserved&quot;: &quot;testMe&quot;, &quot;containerRuntime&quot;: &quot;containerd&quot;}, &quot;containerd&quot;)

# with typo in CRI for Provisioner
case3 = (&quot;baz&quot;, {&quot;kubeReserved&quot;: &quot;testMe&quot;, &quot;containerRuntime&quot;: &quot;qwerty&quot;}, &quot;dockerd&quot;)

test_cases = [
    case1,
    case2,
    case3,
]

@pytest.mark.parametrize(&quot;name, kubelet_configuration, expected_CRI&quot;, test_cases)
def test_cri_provisioner(name: str, kubelet_configuration: t.Optional[dict], expected_CRI: str):

    provisioner = karpenterPayloadProvisioner(name=name, kubelet_configuration=kubelet_configuration)
    assert provisioner.kubelet_configuration[&quot;containerRuntime&quot;] == expected_CRI

</code></pre><pre><code class="language-shell">pytest .
=========================================================== test session starts ============================================================
platform darwin -- Python 3.10.0, pytest-6.2.5, py-1.11.0, pluggy-1.0.0
rootdir: /Users/a.horbach/repository-self/python-monorepo/pydantic-karpenter
plugins: django-4.4.0, cov-3.0.0
collected 3 items

test_karpenter.py ...                                                                                                                [100%]

============================================================ 3 passed in 0.08s =============================================================
</code></pre></details><h2>Links</h2><ul><li><a href="https://github.com/karma-git/Python-Playground/tree/master/pydantic-karpenter">python code</a></li><li><a href="https://github.com/pydantic/pydantic">pydantic</a></li><li><a href="https://github.com/pytest-dev/pytest">pytest</a></li><li><a href="https://github.com/aws/karpenter">karpenter</a></li><li><a href="https://www.youtube.com/watch?v=dOO3GmX6ukU">pydantic digitalize video</a></li></ul>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Terraformer - reverse Terraform]]></title>
        <id>terraformer</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/terraformer"/>
        <updated>2022-12-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Terraformer - reverse Terraform]]></summary>
        <content type="html"><![CDATA[<h2>Описание</h2><p><a href="https://github.com/GoogleCloudPlatform/terraformer">https://github.com/GoogleCloudPlatform/terraformer</a></p><p><strong>Terraformer</strong> - тулза преобразующая существующие облачные ресурсы в <code>terraform код</code>. Может быть полезна в различных кейсах, например: при обучении aws-у и terraform-у - создали ресурсы через console по курсу, а потом дампнули это в terraform код. Либо более классический кейс - описываете существующую инфраструктуру в IaC.</p><h2>Использование</h2><p>:::info</p><p>запустить получилось вот так, но это вряд ли best practices</p><p>:::</p><p>Экспортируем креды доступа к aws-apo</p><pre><code class="language-shell">export AWS_DEFAULT_PROFILE=my-profile  # ~/.aws/credentials
export AWS_ACCESS_KEY_ID=id
export AWS_SECRET_ACCESS_KEY=key
</code></pre><p>Так же нам нужен tf провайдер <code>aws</code>:</p><pre><code class="language-hcl">terraform {
  required_version = &quot;&gt;= 1.3.0&quot;

  required_providers {
    aws = {
      source  = &quot;hashicorp/aws&quot;
      version = &quot;4.42.0&quot;
    }
  }
}
</code></pre><p>Инициализируем провайдер, запускаем terraformer и натравливаем на нужный нам aws ресурс</p><pre><code class="language-shell">terraform init # инициализируем провайдер в директорию ./.terraform
terraformer import aws --resources=route53 --regions=us-east-1 --profile my-profile
terraformer import aws --resources=route53 --regions=us-east-1 --profile my-profile --filter=&quot;Type=route53_zone;Name=tags.Name;Value=my.example.com&quot;
</code></pre>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kubed - secret sync between k8s clusters in different aws accounts]]></title>
        <id>kubed-cross-sync</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/kubed-cross-sync"/>
        <updated>2022-11-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Kubed - secret sync between k8s clusters in different aws accounts]]></summary>
        <content type="html"><![CDATA[<h2>История, Архитектура</h2><h3>1) aws account mc-legacy</h3><p><img src="https://ah-public-pictures.hb.bizmrg.com/it-happens/kubed-cross-sync-1.jpeg" alt="img"/></p><p>Имеется legacy приложение в aws аккаунте:</p><ol><li>В route53 зарегистрирован домен <code>&lt;my-company&gt;.io</code> и аналогичная hosted zone</li><li>В зоне есть запись <code>&lt;my-service&gt;.&lt;my-company&gt;.io</code> , смотрит на <code>&lt;lb&gt;.&lt;my-company&gt;.io</code></li><li>Балансировщик ведет на ASG</li><li>ASG управляет EC2 инсансами на которых работает приложение <code>&lt;my-service&gt;</code></li></ol><h3>2) aws account mc-project</h3><p><img src="https://ah-public-pictures.hb.bizmrg.com/it-happens/kubed-cross-sync-2.jpeg" alt="img"/></p><p>Принимается решение перевезти приложение в kubernetes, для удобства под каждую команду создается свой aws аккаунт и свой k8s кластер:</p><ol><li>В aws поднимается NLB балансировщик <code>&lt;lb-my-project&gt;</code></li><li>Через target groups он смотрит на EC2 инстансы, на которых запущен pod с ingress controller-ом.</li><li>Попадая в pod ингресса, запрос через Ingress перенаправляется на pod-ы за <code>&lt;my-service&gt;</code> с помощью k8s service.</li></ol><h3>3) combine</h3><p><img src="https://ah-public-pictures.hb.bizmrg.com/it-happens/kubed-cross-sync-3.jpeg" alt="img"/></p><p>r53 запись <code>&lt;my-service&gt;.&lt;my-company&gt;.io</code> начинает смотреть на CNAME <code>&lt;lb-my-project&gt;</code>, все работает, но SSL не терминируется.</p><p>Зона <code>&lt;my-company&gt;.io</code> слишком критична для бизнеса, и передавать в нее управление контроллерам типа external-dns, cert-manager не хочется.</p><p>В тоже время aws аккаунтов типа <code>mc-project</code> может быть много, как и кластеров k8s, вручную доставлять секрет с tls сертификатом не хочется.</p><h3>4) Concept</h3><p><img src="https://ah-public-pictures.hb.bizmrg.com/it-happens/kubed-cross-sync-4.png" alt="img"/></p><ol><li>Создается специальный management aws аккаунт и k8s кластер.</li><li>В него каким-то образом доставляется секрет с tls сертификатом <code>*.&lt;my-company&gt;.io</code></li><li>Специальный контроллер <a href="https://github.com/kubeops/config-syncer">kubed</a> синхронизирует секрет <code>*.&lt;my-company&gt;.io</code> в другие кластеры k8s с помощью аннотаций.</li><li>Секрет <code>*.&lt;my-company&gt;.io</code> используется в Ingress, SSL траффик терминируется.</li></ol><h2>Конфигурации</h2><p>:::info</p><p>В последующих конфигурационных файлах роли для <code>mc-mgmt</code> будут называться <code>kubed-master</code>, а <code>mc-project-*</code> - <code>kubed-follower</code></p><p>:::</p><h3>AWS IAM RBAC</h3><p>:::info</p><p>На схеме <code>mc-mgmt</code> = <code>CI</code>, <code>mc-project</code> - <code>Target</code></p><p>:::</p><p><img src="https://ah-public-pictures.hb.bizmrg.com/it-happens/kubed-cross-sync-aws-rbac.png" alt="img"/></p><p>Нужно сделать кросс-аккаунт aws iam rbac роли, для того, чтобы <strong>kubed</strong> из <code>mc-mgmt</code> мог управлять секретами в k8s кластерах других aws аккаунтов, в данном случае <code>mc-project</code>.</p><h4><code>mc-mgmt aka kubed-master</code></h4><div><div value="hcl" label="Terraform"><pre><code class="language-hcl">locals {
  kubed_followers_arns = [
    for _, id in local.aws_accounts_map : &quot;arn:aws:iam::${id}:role/kubed-follower&quot;
  ]
}

module &quot;iam_assumable_role_kubed_master&quot; {
  source  = &quot;terraform-aws-modules/iam/aws//modules/iam-assumable-role-with-oidc&quot;
  version = &quot;4.2.0&quot;

  create_role = true
  role_name   = &quot;kubed-master&quot;

  provider_url = replace(local.cluster_oidc_issuer_url, &quot;https://&quot;, &quot;&quot;)

  role_policy_arns = [
    aws_iam_policy.kubed_master.arn,
    aws_iam_policy.kubed_eks.arn,
  ]

  oidc_fully_qualified_subjects = [
    &quot;system:serviceaccount:kube-system:kubed&quot;
  ]
}

data &quot;aws_iam_policy_document&quot; &quot;kubed_master&quot; {
  statement {
    sid    = &quot;kubedMaster&quot;
    effect = &quot;Allow&quot;
    actions = [
      &quot;sts:AssumeRole&quot;,
    ]
    resources = local.kubed_followers_arns
  }
}

resource &quot;aws_iam_policy&quot; &quot;kubed_master&quot; {
  name   = &quot;kubed-master&quot;
  policy = data.aws_iam_policy_document.kubed_master.json
}

data &quot;aws_iam_policy_document&quot; &quot;kubed_eks&quot; {
  statement {
    sid    = &quot;kubedEks&quot;
    effect = &quot;Allow&quot;
    actions = [
      &quot;eks:DescribeCluster&quot;,
      &quot;eks:ListClusters&quot;
    ]
    resources = [&quot;*&quot;]
  }
}

resource &quot;aws_iam_policy&quot; &quot;kubed_eks&quot; {
  name   = &quot;kubed-eks&quot;
  policy = data.aws_iam_policy_document.kubed_eks.json
}
</code></pre></div><div value="trust" label="Trust policy"><pre><code class="language-json">{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Sid&quot;: &quot;&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: {
                &quot;Federated&quot;: &quot;arn:aws:iam:::&lt;mc-mgmt_id&gt;:oidc-provider/oidc.eks.&lt;aws_region&gt;.amazonaws.com/id/&lt;mc-mgmt_oidc&gt;&quot;
            },
            &quot;Action&quot;: &quot;sts:AssumeRoleWithWebIdentity&quot;,
            &quot;Condition&quot;: {
                &quot;StringEquals&quot;: {
                    &quot;oidc.eks.&lt;aws_region&gt;.amazonaws.com/id/&lt;mc-mgmt_oidc&gt;:sub&quot;: &quot;system:serviceaccount:kube-system:kubed&quot;
                }
            }
        }
    ]
}
</code></pre></div><div value="policy-kubed-master" label="Policy kubed-master"><pre><code class="language-json">{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Sid&quot;: &quot;kubedMaster&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Action&quot;: &quot;sts:AssumeRole&quot;,
            &quot;Resource&quot;: [
                &quot;arn:aws:iam::&lt;mc-project_id&gt;:role/kubed-follower&quot;
            ]
        }
    ]
}
</code></pre></div><div value="policy-kubed-eks" label="Policy kubed-eks"><pre><code class="language-json">{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Sid&quot;: &quot;kubedEks&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Action&quot;: [
                &quot;eks:ListClusters&quot;,
                &quot;eks:DescribeCluster&quot;
            ],
            &quot;Resource&quot;: &quot;*&quot;
        }
    ]
}
</code></pre></div></div><h4><code>mc-project</code> aka kubed-follower</h4><div><div value="hcl" label="Terraform"><pre><code class="language-hcl">locals {
  mc_mgmt_id = &quot;&lt;mc-mgmt_id&gt;&quot;
}

data &quot;aws_iam_policy_document&quot; &quot;kubed_follower_assume&quot; {
  statement {
    sid    = &quot;kubedFollowerAssume&quot;
    effect = &quot;Allow&quot;
    principals {
      identifiers = toset([&quot;arn:aws:iam::${local.mc_mgmt_id}:role/kubed-master&quot;])
      type        = &quot;AWS&quot;
    }
    actions = [
      &quot;sts:AssumeRole&quot;,
    ]
  }
}

data &quot;aws_iam_policy_document&quot; &quot;kubed_follower&quot; {
  statement {
    sid    = &quot;kubedEks&quot;
    effect = &quot;Allow&quot;
    actions = [
      &quot;eks:DescribeCluster&quot;,
      &quot;eks:ListClusters&quot;
    ]
    resources = [&quot;*&quot;]
  }
}


resource &quot;aws_iam_policy&quot; &quot;kubed_follower&quot; {
  name   = &quot;kubed-follower&quot;
  policy = data.aws_iam_policy_document.kubed_follower.json
}


resource &quot;aws_iam_role&quot; &quot;kubed_follower&quot; {
  name                = &quot;kubed-follower&quot;
  description         = &quot;IAM role which allows kubed sync secrets from mc-mgmt to this account&quot;
  assume_role_policy  = data.aws_iam_policy_document.kubed_follower_assume.json
  managed_policy_arns = [aws_iam_policy.kubed_follower.arn]
}
</code></pre></div><div value="trust" label="Trust policy"><pre><code class="language-json">{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Sid&quot;: &quot;kubedFollowerAssume&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: {
                &quot;AWS&quot;: &quot;arn:aws:iam:::&lt;mc-mgmt_id&gt;:role/kubed-master&quot;
            },
            &quot;Action&quot;: &quot;sts:AssumeRole&quot;
        }
    ]
}
</code></pre></div><div value="iam-policy" label="Policy kubed-eks"><pre><code class="language-json">{
    &quot;Statement&quot;: [
        {
            &quot;Action&quot;: [
                &quot;eks:ListClusters&quot;,
                &quot;eks:DescribeCluster&quot;
            ],
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Resource&quot;: &quot;*&quot;,
            &quot;Sid&quot;: &quot;kubedEks&quot;
        }
    ],
    &quot;Version&quot;: &quot;2012-10-17&quot;
}
</code></pre></div></div><h4>ServiceAccount kubed</h4><p>На <strong>ServiceAccount</strong> kubed-master нужно повесить аннотацию:</p><pre><code class="language-yaml">annotations:
  eks.amazonaws.com/role-arn: arn:aws:iam::&lt;mc-mgmt_id&gt;:role/kubed-master
</code></pre><h4>ConfgiMap aws-auth</h4><div><div value="kubed-master" label="kubed master"><pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - &quot;groups&quot;:
      - &quot;system:masters&quot;
      &quot;rolearn&quot;: &quot;arn:aws:iam::&lt;mc-mgmt_id&gt;:role/kubed-master&quot;
      &quot;username&quot;: &quot;&quot;
      ...
</code></pre></div><div value="kubed-follower" label="kubed follower"><pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - &quot;groups&quot;:
      - &quot;system:masters&quot;
      &quot;rolearn&quot;: &quot;arn:aws:iam::&lt;mc-project_id&gt;:role/kubed-follower&quot;
      &quot;username&quot;: &quot;&quot;
      ...
</code></pre></div></div><h3>Docker image</h3><p>Образ от разработчиков scratch, в нем есть только бинарник kubed, нам же нужны утилиты aws для генерирования kubeconfig.</p><pre><code class="language-Dockerfile">FROM appscode/kubed:v0.13.2 as downloader

FROM alpine:3.17

COPY --from=downloader /kubed /usr/bin/kubed

RUN apk add --no-cache \
  curl~=7.86 \
  py3-pip~=22.3 \
  &amp;&amp; pip install --no-cache-dir \
  awscli~=1.27 \
  &amp;&amp; curl -Lo aws-iam-authenticator https://github.com/kubernetes-sigs/aws-iam-authenticator/releases/download/v0.5.9/aws-iam-authenticator_0.5.9_linux_amd64 \
  &amp;&amp; chmod +x aws-iam-authenticator \
  &amp;&amp; mv aws-iam-authenticator /usr/bin/

RUN addgroup --gid 1950 app \
  &amp;&amp; addgroup --gid 1000 app \
  &amp;&amp; adduser \
  --uid 1000 \
  --home /home/app \
  --shell /bin/ash \
  --ingroup app \
  --disabled-password \
  app \
  &amp;&amp; addgroup app app

USER 1000
WORKDIR /home/app

ENTRYPOINT [&quot;/usr/bin/kubed&quot;]
</code></pre><h3>K8s controller</h3><p>В mc-mgmt кластере так же работает обычный интанс kubed-а, установленный <a href="https://github.com/kubeops/config-syncer/tree/master/charts/kubed">helm чартом</a>, из него мы и берем все необходимые k8s RBAC-и.</p><p>:::danger</p><p>Этот способ <strong>деструктивен</strong>, неверная конфигурация kubed-master может реверсировать синхронизацию секретов между namespace-ами. Рекомендация держать специальный кластер для kubed-master</p><p>:::</p><div><div value="cm" label="ConfigMap"><pre><code class="language-yaml">---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubed-master-aws
  namespace: kube-system
data:
  credentials: |-
    [mc-mgmt]
    role_arn = arn:aws:iam::&lt;mc-mgmt_id&gt;:role/kubed-master
    web_identity_token_file = /var/run/secrets/eks.amazonaws.com/serviceaccount/token
    [mc-project]
    role_arn = arn:aws:iam::&lt;mc-project_id&gt;:role/kubed-follower
    source_profile = mc-mgmt
    role_session_name = mc-project
  generate-kubeconfig.sh: |-
    #!/bin/bash
    set -eux

    aws eks update-kubeconfig --name mc-project-k8s --alias mc-project-k8s --profile mc-project

    # NOTE: mc-mgmt-k8s should the last due to current-context
    aws eks update-kubeconfig --name mc-mgmt-k8s --alias mc-mgmt-k8s --profile mc-mgmt
</code></pre></div><div value="deploy" label="Deployment"><pre><code class="language-yaml">---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubed-master
  namespace: kube-system
  labels:
    app.kubernetes.io/name: kubed-master
    app.kubernetes.io/instance: kubed-master
    app.kubernetes.io/version: &quot;v0.13.2&quot;
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kubed-master
      app.kubernetes.io/instance: kubed-master
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kubed-master
        app.kubernetes.io/instance: kubed-master
    spec:
      serviceAccountName: kubed
      # NOTE: kubeconfig-generator
      initContainers:
        - name: kubeconfig-generator
          image: docker.io/my-company/kubed:v0.13.2
          volumeMounts:
            - name: kubeconfig
              mountPath: /srv/kubed
            - name: aws-config
              mountPath: /home/app/.aws
            - name: kubed-master-aws
              mountPath: /home/app/scripts
          command:
            - sh
            - -c
            - |
              mkdir -p /home/app/.aws &amp;&amp;
              cp /home/app/scripts/credentials /home/app/.aws &amp;&amp;
              sh /home/app/scripts/generate-kubeconfig.sh &amp;&amp;
              cp /home/app/.kube/config /srv/kubed/kubeconfig

      containers:
        - name: kubed-master
          image: docker.io/my-company/kubed:v0.13.2
          args:
            - run
            - --v=3
            - --secure-port=8443
            - --audit-log-path=-
            - --tls-cert-file=/var/serving-cert/tls.crt
            - --tls-private-key-file=/var/serving-cert/tls.key
            - --use-kubeapiserver-fqdn-for-aks=true
            - --enable-analytics=false
            - --cluster-name=mc-mgmt
            - --kubeconfig-file=/srv/kubed/kubeconfig
            - --config-source-namespace=prod
          ports:
            - containerPort: 8443
          resources: {}
          volumeMounts:
            - name: kubeconfig
              mountPath: /srv/kubed
            - name: aws-config
              mountPath: /home/app/.aws
            - name: scratch
              mountPath: /tmp
            - name: serving-cert
              mountPath: /var/serving-cert
      volumes:
        # NOTE: we&#x27;d like to generate kubeconfig during initContainer
        - name: kubeconfig
          emptyDir: {}
          # secret:
          #   secretName: kubed # NOTE: contains data.kubeconfig
        - name: aws-config
          emptyDir: {}
        - name: kubed-master-aws
          configMap:
            name: kubed-master-aws
            defaultMode: 0550
        - name: scratch
          emptyDir: {}
        - name: serving-cert
          secret:
            defaultMode: 420
            secretName: kubed-apiserver-cert
      securityContext:
        fsGroup: 1000
</code></pre></div></div><h2>Синхронизация конфигураций</h2><pre><code class="language-yaml">---

apiVersion: v1
kind: ConfigMap
metadata:
  name: cross-acc-sync-demo
  namespace: prod
  annotations:
    kubed.appscode.com/sync-contexts: &quot;mc-project-k8s&quot;
data:
  foo: bar
  spam: eggs
</code></pre><h2>Нюансы работы</h2><p>:::info</p><p>конфигурация: это ConfigMap, Secret</p><p>:::</p><ul><li>Синхронизация возможно только из namespace-а указанного во флагах контроллера в namespace с таким же названием в follower кластерах. При это annotations и labels на конфигурациях в follower кластерах не сохраняется.</li><li>Поводом для синхронизации конфигураций является: перезапуск pod-а контроллера, обновление <code>.data</code> конфигурации. Т.е. если конфигурация будет удалена в follower кластере, она не синхронизуется автоматом.</li><li>Удаление конфигурации в master аккаунте, удалит конфигурацию во всех follower-ах.</li><li>В случае, если в follower кластере есть свой kubed для синхронизации между namespace-ами, то можно добавить annotation-ию вручную и конфигурация разбежится по namespace-ам. Причем обновление <code>.data</code> в master кластере синхронизирует секрет в follower, но не перетрет эту аннотацию.</li></ul><p>Добавляем аннотацию в follower кластере</p><pre><code class="language-shell">kubectl --context mc-project annotate cm cross-acc-sync-demo &quot;kubed.appscode.com/sync=sync/kubed-master=true&quot;
</code></pre><p>Добавляем label на другой namespace в follower кластере, чтобы местный kubed засинхронизировал cm между namespace-ами.</p><pre><code class="language-yaml">---

kind: Namespace
apiVersion: v1
metadata:
  name: env-ahorbach
  labels:
    name: env-ahorbach
    sync/kubed-master: &quot;true&quot;
</code></pre><h2>Ссылки</h2><ul><li><a href="https://dev.to/hayderimran7/adding-cross-account-access-to-eks-5ebh">Imran Hayder: Adding cross-account access to EKS</a></li><li><a href="https://aws.amazon.com/blogs/containers/enabling-cross-account-access-to-amazon-eks-cluster-resources/">AWS: Enabling cross-account access to Amazon EKS cluster resources</a></li><li><a href="https://appscode.com/products/kubed/v0.12.0/guides/config-syncer/inter-cluster/">kubed: Synchronize Configuration across Clusters</a></li><li><a href="https://github.com/kubeops/config-syncer/issues/457">jdepp: KS cross-cluster and cross-namespace syncing issue.</a></li></ul>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lens - build from source]]></title>
        <id>lens-build</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/lens-build"/>
        <updated>2022-11-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Notion Fast Start]]></summary>
        <content type="html"><![CDATA[<h2>История</h2><p>Не запускался Lens 6, быстро проблему решить не получилось, поэтому решил откатиться на предыдущие версии.</p><pre><code class="language-shell">DEBUG=true /Applications/Lens.app/Contents/MacOS/Lens
</code></pre><p>Логи дебага выдавали ошибки, по которым в issues в репозитории на GitHub <a href="https://github.com/lensapp/lens">https://github.com/lensapp/lens</a> не удалось найти полезной информации.</p><p>Как выяснилось - легкого доступа к предыдущим релизам нет, единственный из вариантов это собраться из сорцов.</p><h2>Сборка</h2><pre><code class="language-shell">$ git clone https://github.com/lensapp/lens.git
$ git checkout v5.5.4 # последний из стабильных релизов 5.x.x
$ make build
</code></pre><p>Тут и начинаются грабли, в большей степени связанные с nodejs и несовместимостью версий самой ноды или пакетов.</p><p>Мне для корректировки версии помогла утилита <code>nvm</code> и эта <a href="https://tecadmin.net/install-nvm-macos-with-homebrew/">статья</a></p><pre><code class="language-shell">nvm ls-remote  # смотрим какие варианты нам может предложить менеджер ноды
nvm install lts/fermium # node 15.x
nvm use lts/fermium  # пиним версию ноды в системе
</code></pre><p>В моем случае пина версии ноды хватило, чтобы успешно собрать <code>.dmg</code> пакет.</p>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion]]></title>
        <id>notion-crush-course</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/notion-crush-course"/>
        <updated>2022-03-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Notion Fast Start]]></summary>
        <content type="html"><![CDATA[<h2>Long Story Short</h2><p>Уже пару месяцев использую <code>Notion</code> для заметок, но делал все относительно топорно. У меня было много страничек древовидной структуры и канбан доска с тасками на неделю. Правда недавно взглянул в темплейты от самого <code>Notin</code>-а и скопировал оттуда <em>engineering page</em> (ниже пример под спойлером).</p><p>:::info</p><details><summary>мой канбан борд</summary><p><img src="https://ah-public-pictures.hb.bizmrg.com/it-happens/Screenshot%202022-03-08%20at%2014.00.48.png" alt="img"/></p></details><p>:::</p><p>Посмотрел видео Владлена, нашел много полезного (ниже будет pdf с конспектом)</p><div class="video-wrapper"><iframe height="540" frameborder="0" width="100%" src="https://www.youtube.com/embed/JbJducQmxqw"></iframe></div><p><strong>Конспект</strong>:</p><p><a href="https://ah-public-pictures.hb.bizmrg.com/it-happens/notion-video.pdf">Ссылка на файл</a></p><embed src="https://ah-public-pictures.hb.bizmrg.com/it-happens/notion-video.pdf" type="application/pdf" width="100%" height="600px"/>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GoodNotes - Prometheus]]></title>
        <id>goodnotes-prometheus</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/goodnotes-prometheus"/>
        <updated>2022-03-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[заметки на iPad, Prometheus]]></summary>
        <content type="html"><![CDATA[<h2>iPad. Long Story Short</h2><p>Относительно недавно заимел iPad + Pencil + <a href="https://www.logitech.com/ru-ru/products/ipad-keyboards/combo-touch.html">Logitech Combo Touch</a> для рисования рисунков, заметок и конспектов, легковесной замене ноута в случае инцидентов.</p><ul><li>рисование -&gt; кул с <a href="https://apps.apple.com/us/app/procreate/id425073498">procreate</a></li><li>заметки / конспект -&gt; нравиться с <a href="https://www.goodnotes.com/">goodnotes</a></li><li>замена ноута -&gt; в Logitech отвратный клик на тач и куча проблем самого iPad. Но используя проект <a href="https://github.com/coder/code-server">code-server</a> - я могу работать за iPad. Однако считаю, что поэтому пункту скорее неуд.</li></ul><h2>GoodNotes</h2><p>Софтина как бы примитивная, но можно создавать вот такие конспекты <em>from scratch</em></p><p><img src="https://ah-public-pictures.hb.bizmrg.com/sre/goodnotes-prom.jpg" alt="img"/></p><p>Либо загружать в эту софтину <code>PDF</code>-ы и редактировать уже их:</p><p><img src="https://ah-public-pictures.hb.bizmrg.com/sre/goodnotes-gounited.jpg" alt="img"/></p><p>:::note</p><p>:pencil2: Мне сложно это объяснить, но есть что-то тактильно приятное в том, чтобы писать что-то от руки, при этом конспект не превратиться в мусор.</p><p>Хочется снова пойти в универ :books:
:::</p><h2>Links</h2><ul><li><a href="https://medium.goodnotes.com/how-to-create-good-looking-notes-on-the-ipad-50289cb37d90">How to create good-looking notes on the iPad</a></li><li><a href="https://medium.goodnotes.com/how-to-markup-pdf-ipad-dc6b25c144bb">How to Mark Up a PDF on the iPad</a></li></ul><p><strong>TechWorld with Nana</strong> about prometheus:</p><ul><li><a href="https://www.youtube.com/watch?v=h4Sl21AKiDg">How Prometheus Monitoring works | Prometheus Architecture explained</a></li><li><a href="https://www.youtube.com/watch?v=QoDqxm7ybLc">Setup Prometheus Monitoring on Kubernetes using Helm and Prometheus Operator | Part 1</a></li><li><a href="https://www.youtube.com/watch?v=mLPg49b33sA">Prometheus Monitoring - Steps to monitor third-party apps using Prometheus Exporter | Part 2</a></li></ul><p><strong>Go United</strong></p><ul><li><a href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/docs/ProgrammingLanguages/go/go-init">Article</a></li><li><a href="https://github.com/karma-git/epam-golang-united">Repo</a></li></ul>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Selfmade Vagrant box]]></title>
        <id>selfmade-vagrant-box</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/selfmade-vagrant-box"/>
        <updated>2022-01-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[VagrantBox собирается настолько же просто как и DockerImage!]]></summary>
        <content type="html"><![CDATA[<p>На VagrantCloud не нашел нормальных box-ов с GUI.</p><h2>Процесс</h2><p>:::info
Буду делать аналогии с <em>docker</em>
:::</p><h3>config file</h3><p>Описываем конфигурацию нашего VagrantBox (<em>DockerImage</em>) в формате <code>.hcl</code> (<em>terraform</em>)</p><pre><code class="language-hcl">source &quot;vagrant&quot; &quot;ubuntu&quot; {
  add_force    = true
  communicator = &quot;ssh&quot;
  provider     = &quot;virtualbox&quot;
  source_path  = &quot;ubuntu/focal64&quot;
}

build {
  name    = &quot;learn-packer&quot;
  sources = [
    &quot;source.vagrant.ubuntu&quot;
  ]
}
</code></pre><p>:::tip
Полезные команды:</p><pre><code class="language-shell">packer validate packer.hcl  # валидирует файл
packer fmt .                # форматирует файлы, и кажется, выполняет валидацию
</code></pre><p>:::</p><h3>build</h3><p>С помощью <a href="https://www.packer.io/"><code>packer</code></a> (<em>docker engine</em>) собираем образ.</p><pre><code class="language-shell">packer build packer.hcl
</code></pre><p>Через некоторое время в директории <code>learn-packer</code> появится файл <code>.box</code> (<em>docker_image</em>)</p><h3>push</h3><p>Заливаем получившийся файл на <a href="https://app.vagrantup.com/boxes/search">VagrantCloud</a>. Понадобиться собрать хэш-сумму файла, например через <code>md5</code></p><h3>provisioner</h3><p>:::note
Любимый провиженер - ansible, но можно использовать <code>shell</code>
:::</p><div><div value="hcl" label="packer.hcl"><pre><code class="language-hcl">source &quot;vagrant&quot; &quot;ubuntu&quot; {
  add_force    = true
  communicator = &quot;ssh&quot;
  provider     = &quot;virtualbox&quot;
  source_path  = &quot;ubuntu/focal64&quot;
}

build {
  name    = &quot;learn-packer&quot;
  sources = [
    &quot;source.vagrant.ubuntu&quot;
  ]
  provisioner &quot;ansible&quot; {
    playbook_file = &quot;./ansible/packer-playbook.yml&quot;
  }
}
</code></pre></div><div value="yml" label="packer-playbook.yml"><pre><code class="language-yml">---

- name: install docker engine ubuntu
  hosts: all

  become: true
  become_method: sudo

  tasks:
    - name: 1. Update the apt package index and install packages to allow apt to use a repository over HTTPS
      apt:
        name: 
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
          - lsb-release
          - python3-pip
          - awscli
        state: latest
        update_cache: true

    - name: 2. Add Docker’s official GPG key
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: 3. Add Docker Repository
      apt_repository:
        repo: deb https://download.docker.com/linux/ubuntu focal stable  # FIXME move to var
        state: present

    - name: 4. Install docker engine
      apt:
        name: docker-ce
        state: latest
        update_cache: true

    # Docker post-install steps for ubuntu

    - name: 1. Make sure that group &quot;docker&quot; exists
      group:
        name: docker
        state: present

    - name: 2. Add aws user to docker docker group
      user:
        name: ubuntu
        groups: docker
        append: true
</code></pre></div></div><h3>post-processors</h3><p>:::caution
Не протестировал
:::</p><p>Штуки которые выполняются после сборки, например публикация в <em>VagrantCloud</em> (<em>docker push</em>)</p><p><a href="https://github.com/karma-git/playground/tree/master/environment/vagrant/ubuntu-gui">GitHub repo</a></p>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CKA]]></title>
        <id>cka-commitment</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/cka-commitment"/>
        <updated>2021-02-15T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[начал готовиться к экзамену]]></summary>
        <content type="html"><![CDATA[<p>Буду краток, у вас мало времени: Certified Kubernetes Administrator <a href="https://www.cncf.io/certification/cka/">(CKA)</a> один из крутейших сертификатов.</p><h2>Articles</h2><p>Нашел пару хороших ресурсов, чтобы с чего начать:</p><ul><li><a href="https://devopscube.com/cka-exam-study-guide/">devopscube about CKA</a> - очень много хороших советов и кросс-ссылок, добавил сайт в закладки</li><li><a href="https://medium.com/4th-coffee/passing-the-cka-certified-kubernetes-administrator-exam-in-70-minutes-a-detailed-guide-dc945ba4065d">medium</a> - на контрасте с предыдущей статьей как-то блекло</li><li><a href="https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/?ranMID=39197&amp;ranEAID=AfpokvaRFDA&amp;ranSiteID=AfpokvaRFDA-sXs.MeTftBrEzGs26ywPuw&amp;utm_source=aff-campaign&amp;LSNPUBID=AfpokvaRFDA&amp;utm_medium=udemyads">udemy</a> - для визуалов, учитель из 🇮🇳 , курс как всегда лучше брать за 999р, но можно найти и на пиратских ресурсах</li></ul><h2>About Exam</h2><p>Можно использовать:</p><ul><li>Второй монитор</li><li><a href="https://kubernetes.io/">https://kubernetes.io/</a>*  (да, это вайлдкард, можно читать доку и блог)</li><li><a href="https://github.com/kubernetes/">https://github.com/kubernetes/</a></li></ul><p>Говорят проходить <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way"><code>the hard way</code></a> не обязательно.</p><table><thead><tr><th>Theme</th><th>percentage</th><th>comment</th></tr></thead><tbody><tr><td>Cluster Architecture, Installation &amp; Configuration</td><td>25 %</td><td><code>kubeadm</code>, Container Runtime Interface (CRI)</td></tr><tr><td>Workloads &amp; Scheduling</td><td>15 %</td><td><code>workloads</code> (configure po,deploy,sts,job,cj,ds and etc.); <code>nodes</code> - (drain,cordon,nodeselector,affinity,taint)</td></tr><tr><td>Services &amp; Networking</td><td>20 %</td><td>Container Network Interface (CNI) (networking, connectivity between pods - policy, CoreDNS, etc.)</td></tr><tr><td>Storage</td><td>10 %</td><td>Container Storage Interface (CSI) - sc,pvc,pv - extend pv and etc (?ceph)</td></tr><tr><td>RBAC</td><td>X %</td><td>role based access</td></tr><tr><td>Troubleshooting</td><td>30 %</td><td>see spoiler</td></tr></tbody></table><details><summary>Toggle me!</summary><ul><li><p>What if a node is not ready?</p></li><li><p>What if a pod is frequently restarting, and you need to figure out why?</p></li><li><p>What if all CPU resource is used up and you need to find out which pod consumes the most and why?</p></li><li><p>How to monitor certain resources?</p></li><li><p>How to troubleshoot a failed component?</p><p>:::info
For example, if you want to monitor the CPU resource each pod uses or each node uses, do you know what keyword to search in the official documentation?
:::</p></li></ul></details><h2>Cluster Architecture, Installation &amp; Configuration</h2><p>Завел у себя дома кластер, мастер с одним воркером бегут поверх <code>ubuntu-desktop</code> моего старого ноутбука (4vcpu, 8gb ram), использую <code>vagrant+virtualbox</code>, <code>containerd</code> в качестве рантайма (CRI).</p><p>Мысль в том, что в любой момент могу с относительно минимальными телодвижениями докинуть воркеров с других компьютеров в домашней сети.</p><p>Вот <a href="https://github.com/karma-git/playground/tree/master/environment/vagrant/k8s-cluster">ссылка</a> на код и схемка.</p><p><img src="./static/kubeadm.jpeg" alt="img"/></p>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vagrant - DevOps Environment]]></title>
        <id>vagrant-karma-linux</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/vagrant-karma-linux"/>
        <updated>2021-02-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Собрал Linux для людей]]></summary>
        <content type="html"><![CDATA[<h2>Inspiration</h2><p>Буквально недавно <a href="blog/selfmade-vagrant-box">писал</a> про сборку <code>Vagrant</code>-а, <strong>доделалъ</strong> :tada:, в двух версиях:</p><ul><li>в серверной работаем через ssh </li><li>и gui, установлены разные desktop приложения :computer:</li></ul><p><a href="https://asciinema.org/a/58jLHlUsCZA63uGjIClQcX5r0"><img src="https://asciinema.org/a/58jLHlUsCZA63uGjIClQcX5r0.svg" alt="asciicast"/></a></p><p>:::info &quot;Этапы&quot;</p><ul><li><a href="https://github.com/karma-git/playground/tree/master/environment/vagrant/build">Сборка Packer-ом</a></li><li><a href="https://github.com/karma-git/playground/tree/master/ansible">Ansible</a></li><li><a href="https://app.vagrantup.com/karma-kit">Vagrant Cloud</a></li><li><a href="https://github.com/karma-git/playground/tree/master/environment/vagrant/examples">Vagrantfile examples</a></li></ul><p>:::</p><p>Или схематично:</p><div chart="
  sequenceDiagram
    participant Packer
    participant Vagrant
    participant Ansible
    Packer-&gt;&gt;Vagrant: Launch tmp VM
    Note right of Vagrant: !NOTE: at low level Vagrant uses Virtualbox API
    Vagrant-&gt;&gt;Ansible: Configure tmp VM
    Ansible--&gt;&gt;Vagrant: Done!
    Vagrant--&gt;&gt;Packer: Done!
    %% loop Artifact
    %%     Ansible-&gt;&gt;Packer: Create Vagrant box from current VM state.
    %% end
    note over Packer: Creates Vagrant box from current VM state.
    note over Packer: Releases the Vagrant box on Vagrant Cloud.
"></div><h2>Установка на Windows</h2><p>Проверьте ресурсы вашей host OS:</p><p>CPU</p><pre><code class="language-powershell">WMIC CPU Get DeviceID,NumberOfCores,NumberOfLogicalProcessors
</code></pre><p>Версию OS и общий объем RAM:</p><pre><code class="language-powershell">systeminfo |findstr /c:&quot;OS Name&quot; /c:&quot;Total Physical Memory&quot;
</code></pre><p><img src="static/vagrant-windows.png" alt="img"/></p><p>:::tip &quot;Рекомедованные ресурсы&quot;</p><ul><li>2 vpcu</li><li>4Gi RAM
:::</li></ul><p>Вам потребуется:</p><ul><li><a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a></li><li><a href="https://www.vagrantup.com/docs/installation">Vagrant</a></li></ul><h2>VirtualBox Guest Additions</h2><blockquote><p><a href="https://docs.oracle.com/cd/E36500_01/E36502/html/qs-guest-additions.html">6.4. Installing the VirtualBox Guest Additions</a></p></blockquote><p>:::info</p><p>Это, пожалуй, самое больное в использовании virtualbox - открыть гую на весь экран. Тут я не буду вам давать никаких обещаний, могу лишь накинуть идеи как вам с этим справиться:</p><p>:::</p><h3>vbguest vagrant plugin</h3><p>:::danger
У меня сработало лишь один раз :skull:
:::</p><pre><code class="language-shell">vagrant plugin uninstall vagrant-vbguest
vagrant destroy -f
vagrant up
vagrant plugin install vagrant-vbguest
vagrant vbguest --do install
</code></pre><h3>ansible galaxy</h3><p>Используйте мой <a href="https://github.com/karma-git/playground/tree/master/environment/vagrant/examples/karma-kit-devops-gui">пример</a> - Guest Additions установит ansible роль. </p><p>:::caution</p><p>Гарантию, что у вас все сработает дать невозможно, но скорее всего понадобятся минимальные телодвижения.</p><p>:::</p><h3>Секретный вариант</h3><p>Всегда можно погуглить / посмотреть ютуб на тему как сделать <code>Virtualbox</code> на весь экран :wink:</p><p>Удачи и да прибудет с вами сила!</p><p>:::tip</p><p>Если не смотрели, исправьтесь:</p><div class="video-wrapper"><iframe height="540" frameborder="0" width="50%" src="https://www.youtube.com/embed/n1F_MfLRlX0"></iframe></div><p>:::</p><details><summary>Toggle me!</summary><pre><code>🦖 🦕
</code></pre></details><h2>Links</h2><p>:::info Links</p><p>Ссылки / Статьи которые помогли реализовать идею:</p><details><summary>Links</summary><ul><li><a href="https://www.vagrantup.com/docs/boxes">Vagrant - Boxes</a></li><li><a href="https://www.packer.io/plugins/post-processors/vagrant/vagrant-cloud">Packer - Vagrant</a></li><li><a href="https://opensource.com/article/18/5/manage-your-workstation-ansible-part-3">Manage your workstation with Ansible: Configure desktop settings</a></li><li><a href="https://linuxconfig.org/ubuntu-20-04-gui-installation">Ubuntu 20.04 GUI installation</a></li><li><a href="https://dev.to/mattdark/a-custom-vagrant-box-with-packer-13ke">A custom Vagrant box with Packer</a></li><li><a href="https://blog.popstas.ru/blog/2017/03/26/packer-create-vagrant-box-from-ansible-playbook/">Packer: создаем свои vagrant box и docker image из одного конфига</a></li><li><a href="https://subscription.packtpub.com/book/virtualization-and-cloud/9781786464910/1/ch01lvl1sec12/enabling-virtualbox-guest-additions-in-vagrant">Enabling VirtualBox Guest Additions in Vagrant</a></li><li><a href="https://www.virtualbox.org/manual/ch08.html#vboxmanage-cmd-overview">VBoxManage</a></li></ul><p><strong>github</strong>:</p><ul><li><a href="https://github.com/sys0dm1n/ansible-ubuntu-desktop">sys0dm1n/ansible-ubuntu-desktop</a></li><li><a href="https://github.com/pantarei/ansible-playbook-ubuntu-desktop">pantarei/ansible-playbook-ubuntu-desktop</a></li><li><a href="https://github.com/PeterMosmans/ansible-role-virtualbox-guest">PeterMosmans/ansible-role-virtualbox-guest</a></li><li><a href="https://github.com/dotless-de/vagrant-vbguest/issues/316">dotless-de/vagrant-vbguest/issues/316</a></li><li><a href="https://github.com/mesaguy/ansible-hashicorp">mesaguy/ansible-hashicorp</a></li><li><a href="https://github.com/andrewrothstein/ansible-starship">andrewrothstein/ansible-starship</a></li></ul></details><p>:::</p>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AWS Free Tier и Packer Tutorial]]></title>
        <id>aws-ebs-snapshot</id>
        <link href="https://karma-git.github.io/Andrew-Horbach.github.io-Public/Andrew-Horbach.github.io-Public/blog/aws-ebs-snapshot"/>
        <updated>2021-01-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Используете AWS Free Tier? Настроили Billing Alarms?]]></summary>
        <content type="html"><![CDATA[<h1>Предыстория</h1><p>Когда я только знакомился с AWS по youtube плейлисту, я смастерил <code>VPC</code> в двух <code>AZ</code> с несколькими подсетями. Один из типов подсетей был private - с <code>nat-gateway</code>, в курсах забыли сказать, что они не входят во фритир. За пару дней за 2 гейта накапало около <strong>$6</strong>. Было обидно, я поставил биллинг аларм.</p><p>:::info #!NOTE
Тот самый курс от <a href="https://www.youtube.com/watch?v=8jbx8O3wuLg&amp;list=PLg5SS_4L6LYsxrZ_4xE_U95AtGsIB96k9">Курс ADV-IT</a>
:::</p><h1>История</h1><p>Совсем недавно я учился (на котиках) созданию артефактов с помощью <a href="./blog/selfmade-vagrant-box">packer</a>. После тренировки в AWS я со спокойной душой в console нужного региона убил все <code>AMI</code> и пошел дальше.</p><p>Неделю спустя в почте заметил очередное письмо от AWS (мне иногда на личный gmail аккаунт приходят от них billing репорты, всегда пустые, и приглашения не <a href="https://reinvent.awsevents.com/">re:invent</a>).</p><p><img src="./static/aws-ebs-snapshot-warn.png" alt="alert"/></p><p>Увидел что я потратил 85% <em>&quot;фри-тирного&quot;</em> места под снэпшоты ebs дисков.</p><p>:::info
<a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc&amp;awsf.Free%20Tier%20Types=*all&amp;awsf.Free%20Tier%20Categories=*all">AWS Free Tier</a> - тут можно прочитать сколько вам в месяц выделяется того или иного ресурса бесплатно в рамках фри-тира.
:::</p><p>Ага - из-за негодяя <code>packer</code>-а помимо <code>AMI</code>-шек создаются еще и такие сущности.</p><p><img src="./static/aws-console.png" alt="snapshots"/></p><p>:::tip Мораль</p><ul><li>пермым делом во фри-тире сделайте не рутового пользователя, вторым настройте <a href="https://www.youtube.com/watch?v=XNeAH4dch0g">биллинг алерты</a> (я бы поставил трешхолд на 50% - в моем случае бюджет таял быстро). </li><li>Авторам видео / гайдлайнов, конечно, стоило бы указывать, что это не входит во фри-тир - или входит, но слабые лимиты.
:::</li></ul>]]></content>
        <author>
            <name>Andrew Horbach</name>
            <uri>https://github.com/karma-git</uri>
        </author>
    </entry>
</feed>